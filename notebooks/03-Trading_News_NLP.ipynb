{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing for Signal Generation on News Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pydot, graphviz\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import LSTM, concatenate, Bidirectional\n",
    "from keras.layers import PReLU, ELU, LeakyReLU, GRU, SimpleRNN\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Embedding, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network for processing sequential information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subchannel network for encoding sequential information\n",
    "def subnetwork_channel(input_layer : layers, RNN_architecture : str, units : int, dropout_rate : float) -> layers:\n",
    "    \"\"\"\n",
    "    This function creates a sub network for encoding sequences.\n",
    "    \n",
    "    Inputs:\n",
    "    input_layer - The input keras layer into the subnetwork\n",
    "    RNN_architecture - Name of the RNN type to use\n",
    "    units - Number of units in the RNN\n",
    "    dropout_rate - dropout rate\n",
    "    \n",
    "    Outputs:\n",
    "    batch - Batch Normalized output layer\n",
    "    \n",
    "    \"\"\"\n",
    "    assert RNN_architecture in [\"LSTM\", \"GRU\", \"RNN\"]\n",
    "    \n",
    "    dropout1 = Dropout(rate = dropout_rate)(input_layer)\n",
    "    \n",
    "    if RNN_architecture == \"LSTM\":\n",
    "        rnn_layer = Bidirectional(LSTM(units = units, return_sequences = False))(dropout1)\n",
    "    elif RNN_architecture == \"GRU\":\n",
    "        rnn_layer = Bidirectional(GRU(units = units, return_sequences = False))(dropout1)\n",
    "    elif RNN_architecture == \"RNN\":\n",
    "        rnn_layer = Bidirectional(SimpleRNN(units = units, return_sequences = False))(dropout1)\n",
    "    \n",
    "    dropout2 = Dropout(rate = dropout_rate)(rnn_layer)\n",
    "    batch = BatchNormalization()(dropout2)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network for Generating Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output layer network\n",
    "def output_channel(input_layer : layers ,activation : str, units : int, dropout_rate : float) -> layers:\n",
    "    \"\"\"\n",
    "    This function creates a sub network for outputing classification probabilities.\n",
    "    \n",
    "    Inputs:\n",
    "    input_layer - The input keras layer into the subnetwork\n",
    "    activation  - Name of the activation type to use\n",
    "    units - Number of units in the Dense network\n",
    "    dropout_rate - dropout rate\n",
    "    \n",
    "    Outputs:\n",
    "    output - Softmax output layer\n",
    "    \n",
    "    \"\"\"\n",
    "    assert activation in [\"ReLU\",\"PReLU\", \"ELU\", \"LeakyReLU\"]\n",
    "    \n",
    "    dense = Dense(units)(input_layer)\n",
    "    \n",
    "    if activation == \"PReLU\":\n",
    "        act = PReLU()(dense)\n",
    "    elif activation == \"ELU\":\n",
    "        act = ELU()(dense)\n",
    "    elif activation == \"LeakyReLU\":\n",
    "        act = LeakyReLU()(dense)\n",
    "    elif activation == \"ReLU\":\n",
    "        act = Dense(units, activation='relu')(input_layer)\n",
    "    \n",
    "        \n",
    "    dropout = Dropout(rate = dropout_rate)(act)\n",
    "    batch = BatchNormalization()(dropout)\n",
    "    output = Dense(3,activation='softmax', name = \"Output\")(batch)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put All Parts Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define full model.\n",
    "def define_model(RNN_architecture : str = \"LSTM\", rnn_units : int = 256, dense_units : int = 128,dense_activation : str = \"PReLU\" ,dropout_rate : float = 0.4) -> Model:\n",
    "    \"\"\"\n",
    "    This function defines and compiles a Multichannel RNN for Sentiment Classification.\n",
    "    \n",
    "    Inputs:\n",
    "    RNN_architecture - Name of the RNN type to use\n",
    "    rnn_units - Number of units in the RNN\n",
    "    dense_units - Number of units in the Dense network\n",
    "    dense_activation  - Name of the activation type to use\n",
    "    dropout_rate - dropout rate\n",
    "    \n",
    "    Outputs:\n",
    "    model - A Keras model\n",
    "    \n",
    "    \"\"\"\n",
    "    # Input Layer\n",
    "    shape = (MAX_SEQUENCE_LENGTH,)\n",
    "    input1 = Input(shape = shape, name = \"Main_input\")\n",
    "    \n",
    "    # Channel 1 - GLoVe\n",
    "    embedding1 = Embedding(len(word_index) + 1,\n",
    "              EMBEDDING_DIM,\n",
    "              weights=[glove_embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH,\n",
    "              trainable=False,\n",
    "              input_shape=X_train.shape[1:], name = \"GLoVe_Embedding\")(input1)\n",
    "\n",
    "    net1 = subnetwork_channel(embedding1, RNN_architecture = RNN_architecture, units = rnn_units, dropout_rate = dropout_rate)\n",
    "    \n",
    "    # Channel 2 - Fast Text\n",
    "    embedding2 = Embedding(len(word_index) + 1,\n",
    "              EMBEDDING_DIM,\n",
    "              weights=[fasttext_embedding_matrix],\n",
    "              input_length=MAX_SEQUENCE_LENGTH,\n",
    "              trainable=False,\n",
    "              input_shape=shape, name = \"FastText_Embedding\")(input1)\n",
    "\n",
    "    net2 = subnetwork_channel(embedding2, RNN_architecture = RNN_architecture, units = rnn_units, dropout_rate = dropout_rate)\n",
    "    \n",
    "    # Merge\n",
    "    merged = concatenate([net1,net2], name =\"Merge\")\n",
    "    # Output channel\n",
    "    output = output_channel(merged, activation = dense_activation, units = dense_units, dropout_rate = dropout_rate)\n",
    "    \n",
    "    # Compile \n",
    "    model = Model(inputs = input1, outputs = output)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = Adam(0.002), metrics = ['categorical_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = define_model(RNN_architecture = \"LSTM\",\n",
    "                     rnn_units= 256,\n",
    "                     dense_units = 128,\n",
    "                     dense_activation = \"ReLU\",\n",
    "                     dropout_rate = 0.4)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_name = 'imgs/multichannel-bidirectionalLSTM.png'\n",
    "plot_model(model,show_shapes=True,to_file=pic_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/multichannel-bidirectionalLSTM.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Train\n",
    "tensorboard = TensorBoard(log_dir='tasks/tensorboard/logs/')\n",
    "model.fit(X_train, y_train, epochs = 10, batch_size = 1024, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Click [here](/tensorboard/) to start TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the testing accuracy\n",
    "val_loss, val_catergorical_accuracy = model.evaluate(X_test,y_test)\n",
    "print(\"Validation Accuracy: {:.1f}\".format(val_catergorical_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model was able to achieve ~79% accuracy. According to research on sentiment analysis and classification, human raters may only agree with each other about 80% of the time. Due to the nature of sentiment analysis, the outcome a reader arrives at can be very subjective depending on how the reader interprets the words, tone or phrasing of the text. Thus, a model that predicts with 100% accuracy may still disagree with a human 20% of the time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Re-tune Neural Network Parameters\n",
    "Try experimenting with different parameters in the neural network.\n",
    "In the function 'define_model'\n",
    "    - 'RNN_architecture' can be one of: \"RNN\", \"GRU\", \"LSTM\".\n",
    "    - 'rnn_units' are the number of units in the RNN\n",
    "    - 'dense_units' are the number of units in the dense network\n",
    "    - 'dense_activation' can be one of: \"PReLU\", \"LeakyReLU\", \"ELU\", \"ReLU\"\n",
    "    - 'dropout_rate' rate of dropout throughout the network"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
