{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing for Signal Generation on News Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usecase\n",
    "\n",
    "1. Building Deep Neural Networks to process and interpret news data.\n",
    "2. Understand the various building blocks of making a NLP system.\n",
    "3. Backtest and apply the models to news data for signal generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background/Concepts\n",
    "\n",
    "**What is NLP**\n",
    "\n",
    "Natural Language Processing (NLP) is a field of artificial intelligence that models the interaction between human (natural) language and computers. The goal of an NLP models is to extract information or knowledge from a piece of text.\n",
    "\n",
    "**Sentiment Analysis**\n",
    "\n",
    "This project is about sentiment analysis, which is one of the basic task in NLP. Sentiment analysis is the process of computationally identifying and categorizing opinions expressed in a piece of text, especially in order to determine whether the writer's attitude towards a particular topic, product, etc. is positive, negative, or neutral. \n",
    "\n",
    "**Sentiment Analysis for News**\n",
    "\n",
    "It is undeniable that following the news release of a story with strong impact on an industry or company the market prices intraday will react accordingly. For the average person with an investment account, the news is a substantial signal in the decision making process to buy/sell a certain stock. However to make a systematic approach to trading on news signals is simply impossible for a human to do manually. \n",
    "\n",
    "- There are 92000+ news article released per day\n",
    "- An average human can read at a speed of 200-250 words per minute\n",
    "- Reading at this rate, for 8 hours continuously, a human may process up to 40-50 articles per day. This calculation disregards the time it takes to find the articles and make any analysis.\n",
    "\n",
    "In Finance, the efficiency and speed at which you process information can be vital for making well-informed, smart decisions. We can leverage deep learning in order to train models that provide sentiment scores for headlines, articles, tweets, and posts. These sentiments can produce valuable signals to support a buy/sell/hold decision as well as valuation models. \n",
    "\n",
    "\n",
    "\n",
    "**How does Computer Understand Text**\n",
    "\n",
    "Maching learning and deep learning algorithms can't directly take character/string as input.Therefore, We first have to represent the features(meaning, syntactic structure, ...) from the text by numerical data strcutures before we apply any ML algorithm. The graph belows shows how this process works. The concept shown in the graph will be detailed explained below.\n",
    "<img src=\"../imgs/understand_text.png\">\n",
    "\n",
    "**Word Embeddings**\n",
    "\n",
    "A Word Embedding is a mathematical mapping from a vast dimensional space where each word occupies a dimension to a reduced-dimension, continuous vector space. Typically a large corpus of text is used to train and develop these embeddings.\n",
    "The embedded word vectors captures the meaning of words. Each dimension in these vector cpatures part of meaning of the corresponding word. This allows the result vector to have several neat features:\n",
    "* Nearest Neighbors - the cosine similarity between two word vectors is can be an effective measure of the linguistic or semantic similarity of the corresponding words.\n",
    "* Linear substructures - in contrast to the cosine similarity, an great deal of information is captured in the vector differences between word vectors. GloVe tries to captures the information pertaining to the relationships between words and this can be showcased through the vector differences. \n",
    "<img src=\"../imgs/Word-Vectors.png\">\n",
    "There are various methods to generating word embeddings. These include neural networks, probabilistic models, dimensionality reduction etc. In this project we will use pretrained word embeddings, which means we don't have to worry about generating them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Complete Model\n",
    "<img src=\"../imgs/model_overview.png\">\n",
    "\n",
    "**Multi-channel LSTM network**\n",
    "\n",
    "Different word embedings contain different information from the text. In this project, we used two different embedings (embeding1 and embeding2) followed by two LSTM (net1 and net2) to generate the features. This provides the network access to more features from seperate word embedings, which leads to more robust result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toolkit Packages\n",
    "\n",
    "These are all very popular free Python libraries to work with machine learning and natural language processing. Data types (e.g. numpy arrays and pandas dataframes) are well-supported among these libraries and can be easily converted to one another.\n",
    "\n",
    "* __Data Manipulation__\n",
    "  * _numpy_: Manipulation for large, multi-dimensional arrays and matrices\n",
    "    * Has a large collection of high-level mathematical functions (e.g. element-wise log function)\n",
    "    * Typical data structure: numpy array\n",
    "  * _pandas_: Manipulation and analysis on numerical tables and time series\n",
    "    * Typical data structure: pandas dataframe\n",
    "* __Machine Learning__\n",
    "  * _sklearn_: light weight machine learning packaged tools for classification, regression, and clustering algorithms\n",
    "    * see https://scikit-learn.org/stable/documentation.html for guide and documentation\n",
    "  * _tensorflow_: Popular deep neural network frameworks.\n",
    "    * see https://www.tensorflow.org for guide and documentation\n",
    "  * _keras_: high-level API to build and train deep learning models in tensorflow.\n",
    "    * see https://www.tensorflow.org/guide/keras for guide and documentation\n",
    "  \n",
    "* __Natural Language Processing__\n",
    "  * _nltk_: Natural Language Toolkit\n",
    "    * Tools include classification, tokenization, stemming, tagging, parsing, and semantic reasoning\n",
    "  * _Word Embedings_: files that could be read in to generate the embeding matrix  \n",
    "    * GloVe: Word embeding. See https://nlp.stanford.edu/projects/glove/ for more details.\n",
    "    * FastText: Word embeding. See https://fasttext.cc/docs/en/crawl-vectors.html for more details.\n",
    "* __Utility__\n",
    "  * _tqdm_: Offers progress bar over iterable (e.g. for loop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- Glove: https://nlp.stanford.edu/projects/glove/\n",
    "- Fasttext: https://fasttext.cc/\n",
    "- News articles per day: https://www.slideshare.net/chartbeat/mockup-infographicv4-27900399\n",
    "- News data source: https://github.com/philipperemy/financial-news-dataset\n",
    "- Word embeddings: https://en.wikipedia.org/wiki/Word_embedding \n",
    "- Natural Language Processing: https://en.wikipedia.org/wiki/Natural-language_processing\n",
    "- Sentiment Analysis: https://en.wikipedia.org/wiki/Sentiment_analysis\n",
    "- keras: https://www.tensorflow.org/guide/keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
